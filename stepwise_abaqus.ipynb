{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from RL.surrogate import SurrogateNet_multiMLP, geometric_position, geometric_reshape, visualize\n",
    "from calc_init_param import calc_next_param\n",
    "from core.param_util.param_tools import gen_param_csv\n",
    "from automation import run_cmd\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "import shutil\n",
    "from RL.surrogate_springback import SurrogateNet_springback\n",
    "import matplotlib.pyplot as plt\n",
    "from core.param_util.param_tools import gen_param_csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bending_env(gym.Env):\n",
    "    def __init__(self, n_actions, episode=1000):\n",
    "\n",
    "        # Define the state space size\n",
    "        self.state_space = spaces.Box(low=0, high=200, shape=(3, 7, 72), dtype=np.float32)\n",
    "\n",
    "        # Define the action space size\n",
    "        self.action_space = spaces.Discrete(n=n_actions, start=1)\n",
    "\n",
    "        # Initialize the current state with the stress distribution after pre-stretch\n",
    "        self.state = None\n",
    "\n",
    "        self.pre_idx = None\n",
    "        self.pre_param = [321.1,0.0,0.0,0,-0.0,0.0]  # Pre-stretch length\n",
    "\n",
    "        self.strip_length = 40\n",
    "        self.pre_length = 0.1\n",
    "        self.k = 0.05\n",
    "\n",
    "        # Surrogate model\n",
    "        self.model = SurrogateNet_multiMLP(1512, 1512)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
    "        checkpoint = torch.load(\"/Optimizing_bending_parameter/RL/Surrogate_model.pth\")\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        \n",
    "        # Bending Parameter list\n",
    "        self.param_list = []  # To be considered: add the pre-stretch parameter to it\n",
    "\n",
    "        self.action_list = []  # Record series of actions for each episode for future use\n",
    "\n",
    "        self.max_step = 15  # Max number of bending steps\n",
    "\n",
    "        self.num_episode = episode\n",
    "\n",
    "        self.mould_name = \"test\" + str(self.num_episode)\n",
    "\n",
    "        self.rec = geometric_reshape()\n",
    "        \n",
    "        # Some useful data path\n",
    "        self.data_path_2 = \"./data/mould_output/\" + self.mould_name\n",
    "        self.data_path_1 = \"./data/model/\" + self.mould_name\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset the environment\n",
    "        self.num_episode += 1\n",
    "        self.mould_name = \"test\" + str(self.num_episode)\n",
    "        self.data_path_2 = \"./data/mould_output/\" + self.mould_name\n",
    "        self.data_path_1 = \"./data/model/\" + self.mould_name\n",
    "\n",
    "        # Generate curve and mould for this episode\n",
    "        print(self.mould_name)\n",
    "        '''\n",
    "        if not os.path.exists(self.data_path_2):\n",
    "            os.makedirs(self.data_path_2)\n",
    "        if not os.path.exists(self.data_path_1):\n",
    "            os.makedirs(self.data_path_1)\n",
    "        cmd = ['python ', 'gen_curve_and_mould.py', self.mould_name]\n",
    "        # print(cmd)\n",
    "        \n",
    "        run_cmd(cmd)\n",
    "        shutil.copy(self.data_path_2 + '/mould.stp', self.data_path_1)\n",
    "        '''\n",
    "\n",
    "        '''\n",
    "            Initialize the state with the stress distribution after pre-stretch.\n",
    "            Since the pre-strech steps are all the same for each test, we simply used the one of test 0.\n",
    "        '''\n",
    "        \n",
    "        csv_path = \"/Optimizing_bending_parameter/data/model/test0/simulation/strip_mises_Step-0.csv\"\n",
    "        if os.path.exists(csv_path):\n",
    "            df = pd.read_csv(csv_path)\n",
    "            x = df[\"S_Mises\"]\n",
    "            x = torch.tensor(x, dtype=torch.float32)\n",
    "        self.state = x\n",
    "        # geometric_position(self.rec, x)\n",
    "\n",
    "        self.action_list = []  # Empty the action series\n",
    "        self.param_list = []  # Empty the param list\n",
    "        self.pre_idx = None  # Reset pre_idx\n",
    "\n",
    "        # Perform the pre-stretch step\n",
    "        next_param, self.pre_idx = calc_next_param(\"./data/mould_output/\" + \"test0\", 0, \n",
    "                                                    self.strip_length, \n",
    "                                                    self.pre_length, \n",
    "                                                    self.k, \n",
    "                                                    self.pre_idx)\n",
    "        self.param_list.append(next_param)\n",
    "        # visualize(self.state, self.state, self.rec)\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        self.action_list.append(action)\n",
    "        # print(self.state) \n",
    "\n",
    "        # Adding the next parameter to the list\n",
    "        next_param, self.pre_idx = calc_next_param(\"./data/mould_output/\" + \"test0\", action, \n",
    "                                                    self.strip_length, \n",
    "                                                    self.pre_length, \n",
    "                                                    self.k, \n",
    "                                                    self.pre_idx)\n",
    "        self.param_list.append(next_param)\n",
    "        t = (np.array(next_param - np.array(self.param_list[-2]))).tolist()\n",
    "        t = torch.tensor(t[:2] + [t[5]], dtype=torch.float32)\n",
    "        # print(t)\n",
    "\n",
    "        # Execute the given action and return the next state, reward, and whether the episode is done\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            self.state = self.model(self.state, t)  # Surrogate model as transition function\n",
    "            # visualize(self.state, self.state, self.rec)\n",
    "        \n",
    "        # Check if the episode is done and calculate the reward\n",
    "        if self.pre_idx == 1999 or len(self.action_list) == self.max_step:\n",
    "            reward = 100 - self.reward_surrogate(self.state)\n",
    "            # reward = 200 - max(self.state) - self.reward_surrogate(self.state)\n",
    "            done = True\n",
    "        else:\n",
    "            # reward = 100 - max(self.state)\n",
    "            reward = -5\n",
    "            done = False  \n",
    "        # print(\"Reward in this step: {}\".format(reward))\n",
    "        return self.state, reward, done, {}\n",
    "\n",
    "    def reward_surrogate(self, final_state):\n",
    "        self.reward_model = SurrogateNet_springback(self.rec)\n",
    "        checkpoint = torch.load(\"/Optimizing_bending_parameter/RL/Surrogate_springback_model.pth\")\n",
    "        self.reward_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        final_state = final_state.double()\n",
    "        \n",
    "        self.reward_model.eval()\n",
    "        with torch.no_grad():\n",
    "            reward = self.reward_model(final_state)\n",
    "        # print(reward)\n",
    "        return reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, rec, n_actions, alpha):\n",
    "        super(Actor, self).__init__()\n",
    "        self.conv_module = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "       \n",
    "        # Define the final fully connected layer for generating the action\n",
    "        self.fc1 = nn.Linear(32 * 18 * 1 * 1, 64)  \n",
    "        self.fc2 = nn.Linear(64, n_actions)\n",
    "        self.rec = rec\n",
    "        self.relu = nn.ReLU()\n",
    "        # self.softmax = F.softmax()\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
    "\n",
    "    def forward(self, stress):\n",
    "        x = torch.tensor(geometric_position(self.rec, stress), dtype=torch.float32)\n",
    "        \n",
    "        # print(stress)\n",
    "        x = self.conv_module(x)\n",
    "            \n",
    "        x = x.view(-1, 32 * 18 * 1 * 1)  # Flatten the output\n",
    "            \n",
    "        # Fully connected layers with ReLU activation\n",
    "        x = self.relu(self.fc1(x))\n",
    "        # print(self.fc2(x))\n",
    "        probs = F.softmax(self.fc2(x))\n",
    "        # print(probs)\n",
    "        return probs\n",
    "\n",
    "# Define the Critic network\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, rec, alpha):\n",
    "        super(Critic, self).__init__()\n",
    "        self.conv_module = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "       \n",
    "        # Define the final fully connected layer for generating the action\n",
    "        self.fc1 = nn.Linear(32 * 18 * 1 * 1, 64)  \n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        self.rec = rec\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
    "\n",
    "    def forward(self, stress):\n",
    "        x = torch.tensor(geometric_position(self.rec, stress), dtype=torch.float32)\n",
    "        # print(stress)\n",
    "        x = self.conv_module(x)\n",
    "        x = x.view(-1, 32 * 18 * 1 * 1)  # Flatten the output\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, n_actions, env, gamma=0.99, lr=1e-1):\n",
    "        super(Agent, self).__init__()\n",
    "        self.env = env\n",
    "        self.actor = Actor(env.rec, n_actions, alpha=lr)\n",
    "        self.critic = Critic(env.rec, alpha=lr)\n",
    "        self.gamma = gamma\n",
    "        self.log_probs = None\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        probs = self.actor.forward(stress=observation)\n",
    "        # print(probs)\n",
    "        dist = Categorical(probs)\n",
    "        self.log_probs = dist.sample()\n",
    "        action = dist.sample().numpy()[0]\n",
    "        return action\n",
    "        \n",
    "    def learn(self, state, new_state, reward, done):\n",
    "        self.actor.optimizer.zero_grad()\n",
    "        self.critic.optimizer.zero_grad()\n",
    "\n",
    "        value_1 = self.critic.forward(state)\n",
    "        value_2 = self.critic.forward(new_state)\n",
    "\n",
    "        delta = reward + self.gamma * value_2 * (1-int(done)) - value_1\n",
    "\n",
    "        critic_loss = delta ** 2\n",
    "        actor_loss = -self.log_probs * delta\n",
    "        param = self.actor.parameters()\n",
    "\n",
    "        (actor_loss + critic_loss).backward()\n",
    "        self.actor.optimizer.step()\n",
    "        self.critic.optimizer.step()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1001\n",
      "[[321.1, 0.0, 0.0, 0.0, -0.0, 0.0], [321.09783027037633, 4.34828737170004, 0.0, 0.0, -0.0, 0.013754938346564827]]\n",
      "gen_abaqus_model_step.py Failure\n",
      "[[321.1, 0.0, 0.0, 0.0, -0.0, 0.0], [321.09783027037633, 4.34828737170004, 0.0, 0.0, -0.0, 0.013754938346564827], [321.0582287785843, 7.54062586307981, 0.0, 0.0, -0.0, 0.024139717126619047]]\n",
      "gen_abaqus_model_step.py Failure\n"
     ]
    }
   ],
   "source": [
    "env = bending_env(n_actions=5)\n",
    "env.reset()\n",
    "for i in range(2):\n",
    "    env.step(4)\n",
    "    print(env.param_list)\n",
    "    mould_name = \"test00\"\n",
    "    data_path_2 = \"./data/mould_output/\" + mould_name\n",
    "    data_path_1 = \"./data/model/\" + mould_name\n",
    "    rel_param_list = gen_param_csv(\n",
    "                param_list=env.param_list,\n",
    "                output_path=data_path_2,\n",
    "                pre_length=0.1,\n",
    "                version=\"base\",\n",
    "            )\n",
    "\n",
    "    tasks = ['gen_abaqus_model_step.py'] # , 'gen_spring_back_model.py', 'data_collection.py']\n",
    "\n",
    "    for i in range(len(tasks)):\n",
    "        cmd = ['python ', tasks[i], mould_name, i+1]\n",
    "        run_cmd(cmd)\n",
    "    \n",
    "# springback_path = data_path_1 + \"/simulation/springback_output.csv\" \n",
    "# springback = pd.read_csv(springback_path)[\"Springback\"]\n",
    "# reward = max(springback.tolist()) * 10 # Reward is the max springback deviation, so the less the better\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.18 ('bending_parameter')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "bb5682a02b22986d5da7cf5ad9a87df9e6aaf685707959f756f6733e237bfd4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
